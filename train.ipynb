{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "47f4f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "from transformers import BertModel, BertTokenizer, get_linear_schedule_with_warmup\n",
    "from typing import List\n",
    "from torch.utils.data import DataLoader, RandomSampler, TensorDataset, SequentialSampler\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed) \n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "448331f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger\n",
    "import datetime\n",
    "import logging\n",
    "import time\n",
    "\n",
    "\n",
    "def custom_logger(name: str, log_level: str):\n",
    "\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(log_level)\n",
    "    logger.propagate = False\n",
    "    logger.handlers = []\n",
    "    #  自定义log 格式\n",
    "    # formatter = logging.Formatter('[%(asctime)s]-[%(name)s:%(levelname)s]-[%(process)d-%(thread)d]:%(message)s')\n",
    "    formatter = logging.Formatter('[%(asctime)s]-[%(name)s:%(levelname)s]: %(message)s')\n",
    "    #  使用utc-时间\n",
    "    def _utc8_aera(timestamp):\n",
    "        now = datetime.datetime.utcfromtimestamp(timestamp) + datetime.timedelta(hours=8)\n",
    "        return now.timetuple()\n",
    "\n",
    "    formatter.converter = _utc8_aera\n",
    "    custom_handler = logging.StreamHandler()\n",
    "    custom_handler .setFormatter(formatter)\n",
    "\n",
    "    logger.addHandler(custom_handler)\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8d82f8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "def tokenize_corpus(text_list: List[str], tokenizer: BertTokenizer) -> List[List[int]]:\n",
    "    tokenized_data = []\n",
    "    for text in tqdm(text_list):\n",
    "        token = tokenizer.tokenize(text)\n",
    "        token = [\"[CLS]\"] + token\n",
    "        token = tokenizer.convert_tokens_to_ids(token)\n",
    "        tokenized_data.append(token)\n",
    "    return tokenized_data\n",
    "\n",
    "\n",
    "def mask_token_ids(token_ids: List[List[int]], padded_size):\n",
    "    input_ids = []\n",
    "    input_types = []\n",
    "    input_masks = []\n",
    "\n",
    "    for token in tqdm(token_ids):\n",
    "        types = [0] * (len(token))\n",
    "        masks = [1] * (len(token))\n",
    "\n",
    "        # pad\n",
    "        if len(token) < padded_size:\n",
    "            types = types + [1] * (padded_size - len(token))\n",
    "            masks = masks + [0] * (padded_size - len(token))\n",
    "            token = token + [0] * (padded_size - len(token))\n",
    "        else:\n",
    "            types = types[:padded_size]\n",
    "            masks = masks[:padded_size]\n",
    "            token = token[:padded_size]\n",
    "\n",
    "        assert len(token) == len(masks) == len(types) == padded_size\n",
    "\n",
    "        input_ids.append(token)\n",
    "        input_types.append(types)\n",
    "        input_masks.append(masks)\n",
    "\n",
    "    return input_ids, input_types, input_masks\n",
    "\n",
    "def split_train_dataset(input_ids: List[List[int]], input_types: List[List[int]],\n",
    "                        input_masks: List[List[int]], labels: List[List[int]], batch_size: int, ratio: float) -> (\n",
    "        DataLoader, DataLoader):\n",
    "    random_order = list(range(len(input_ids)))\n",
    "    np.random.shuffle(random_order)\n",
    "\n",
    "    input_ids_train = np.array([input_ids[i] for i in random_order[:int(len(input_ids) * ratio)]])\n",
    "    input_types_train = np.array([input_types[i] for i in random_order[:int(len(input_ids) * ratio)]])\n",
    "    input_masks_train = np.array([input_masks[i] for i in random_order[:int(len(input_ids) * ratio)]])\n",
    "    y_train = np.array([labels[i] for i in random_order[:int(len(input_ids) * ratio)]])\n",
    "\n",
    "    input_ids_test = np.array(\n",
    "        [input_ids[i] for i in random_order[int(len(input_ids) * ratio):]])\n",
    "    input_types_test = np.array(\n",
    "        [input_types[i] for i in random_order[int(len(input_ids) * ratio):]])\n",
    "    input_masks_test = np.array(\n",
    "        [input_masks[i] for i in random_order[int(len(input_ids) * ratio):]])\n",
    "    y_test = np.array([labels[i] for i in random_order[int(len(input_ids) * ratio):]])\n",
    "\n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids_train),\n",
    "                               torch.LongTensor(input_types_train),\n",
    "                               torch.LongTensor(input_masks_train),\n",
    "                               torch.LongTensor(y_train))\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_loader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "    valid_data = TensorDataset(torch.LongTensor(input_ids_test),\n",
    "                               torch.LongTensor(input_types_test),\n",
    "                               torch.LongTensor(input_masks_test),\n",
    "                               torch.LongTensor(y_test))\n",
    "    valid_sampler = SequentialSampler(valid_data)\n",
    "    valid_loader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_size, drop_last=True)\n",
    "    return train_loader, valid_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "060a470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = custom_logger('train', 'INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0c1d16b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "def get_data(file_path, padded_size):\n",
    "    corpus = []\n",
    "    labels = []\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.dropna(inplace=True)\n",
    "    for i in range(len(df)):\n",
    "        text = df.iloc[i][\"微博中文内容\"].strip()\n",
    "        label = df.iloc[i][\"情感倾向\"]\n",
    "        if label not in ['-1', '0', '1']:\n",
    "            continue\n",
    "        label=int(label)\n",
    "        if label == -1:\n",
    "            label= 2\n",
    "        corpus.append(text)\n",
    "        labels.append(label)\n",
    "    assert len(corpus) == len(labels)\n",
    "    corpus = [text[0:padded_size] for text in corpus]\n",
    "    return corpus, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50c6f33f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>微博id</th>\n",
       "      <th>微博发布时间</th>\n",
       "      <th>发布人账号</th>\n",
       "      <th>微博中文内容</th>\n",
       "      <th>微博图片</th>\n",
       "      <th>微博视频</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4456068992182160</td>\n",
       "      <td>01月01日 23:38</td>\n",
       "      <td>-精緻的豬豬女戰士-</td>\n",
       "      <td>#你好2020#新年第一天元气满满的早起出门买早饭结果高估了自己抗冻能力回家成功冻发烧（大概...</td>\n",
       "      <td>['https://ww2.sinaimg.cn/thumb150/745aa591ly1g...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4456424178427250</td>\n",
       "      <td>01月02日 23:09</td>\n",
       "      <td>liujunyi88</td>\n",
       "      <td>大宝又感冒鼻塞咳嗽了，还有发烧。队友加班几天不回。感觉自己的情绪在家已然是随时引爆的状态。情...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4456797466940200</td>\n",
       "      <td>01月03日 23:53</td>\n",
       "      <td>ablsa</td>\n",
       "      <td>还要去输两天液，这天也太容易感冒发烧了，一定要多喝热水啊?</td>\n",
       "      <td>['https://ww3.sinaimg.cn/orj360/006fTidCly1gaj...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4456791021108920</td>\n",
       "      <td>01月03日 23:27</td>\n",
       "      <td>喵吃鱼干Lynn</td>\n",
       "      <td>我太难了别人怎么发烧都没事就我一检查甲型流感?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4457086404997440</td>\n",
       "      <td>01月04日 19:01</td>\n",
       "      <td>我的发小今年必脱单</td>\n",
       "      <td>果然是要病一场的喽回来第三天开始感冒今儿还发烧了喉咙眼睛都难受的一匹怎么样能不经意让我的毕设...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>4464179518243680</td>\n",
       "      <td>01月24日 08:46</td>\n",
       "      <td>一隻敦敦仔</td>\n",
       "      <td>「2020的黑天鹅事件」&gt;2019-nCov?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>4464274073923100</td>\n",
       "      <td>01月24日 15:02</td>\n",
       "      <td>艺哥的明信片</td>\n",
       "      <td>心灵鸡汤#武汉加油#我们所有人，和我们这个国家一起，正在经历着一场这个星球上史无前例的考验...</td>\n",
       "      <td>['https://ww1.sinaimg.cn/orj360/b633842dgy1gb7...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>4464289160945130</td>\n",
       "      <td>01月24日 16:02</td>\n",
       "      <td>金融柑仔店</td>\n",
       "      <td>武大人民医院：发热咳嗽并非新冠肺炎的唯一首发症状(来自@界面新闻)武汉大学人民医院研究组1月...</td>\n",
       "      <td>['https://ww1.sinaimg.cn/orj360/72c6e287ly1gb7...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>4465347950314820</td>\n",
       "      <td>01月27日 14:09</td>\n",
       "      <td>G顾曲周郎Z</td>\n",
       "      <td>闭关第二天发现一根白发2019-nCoV?</td>\n",
       "      <td>['https://ww1.sinaimg.cn/orj360/65eccabcly1gbb...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>4465492650005690</td>\n",
       "      <td>01月27日 23:44</td>\n",
       "      <td>牛牛酱耶嘿</td>\n",
       "      <td>//@高反台:昨天还在想如果有动画短片就好了，今天就有了，视频果然更直接有效吧。</td>\n",
       "      <td>['https://wx1.sinaimg.cn/orj480/00721Ezdly1gbb...</td>\n",
       "      <td>['https://f.video.weibocdn.com/001wQVdllx07Aus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  微博id        微博发布时间       发布人账号  \\\n",
       "0     4456068992182160  01月01日 23:38  -精緻的豬豬女戰士-   \n",
       "1     4456424178427250  01月02日 23:09  liujunyi88   \n",
       "2     4456797466940200  01月03日 23:53       ablsa   \n",
       "3     4456791021108920  01月03日 23:27    喵吃鱼干Lynn   \n",
       "4     4457086404997440  01月04日 19:01   我的发小今年必脱单   \n",
       "...                ...           ...         ...   \n",
       "9995  4464179518243680  01月24日 08:46       一隻敦敦仔   \n",
       "9996  4464274073923100  01月24日 15:02      艺哥的明信片   \n",
       "9997  4464289160945130  01月24日 16:02       金融柑仔店   \n",
       "9998  4465347950314820  01月27日 14:09      G顾曲周郎Z   \n",
       "9999  4465492650005690  01月27日 23:44       牛牛酱耶嘿   \n",
       "\n",
       "                                                 微博中文内容  \\\n",
       "0     #你好2020#新年第一天元气满满的早起出门买早饭结果高估了自己抗冻能力回家成功冻发烧（大概...   \n",
       "1     大宝又感冒鼻塞咳嗽了，还有发烧。队友加班几天不回。感觉自己的情绪在家已然是随时引爆的状态。情...   \n",
       "2                         还要去输两天液，这天也太容易感冒发烧了，一定要多喝热水啊?   \n",
       "3                               我太难了别人怎么发烧都没事就我一检查甲型流感?   \n",
       "4     果然是要病一场的喽回来第三天开始感冒今儿还发烧了喉咙眼睛都难受的一匹怎么样能不经意让我的毕设...   \n",
       "...                                                 ...   \n",
       "9995                            「2020的黑天鹅事件」>2019-nCov?   \n",
       "9996  心灵鸡汤#武汉加油#我们所有人，和我们这个国家一起，正在经历着一场这个星球上史无前例的考验...   \n",
       "9997  武大人民医院：发热咳嗽并非新冠肺炎的唯一首发症状(来自@界面新闻)武汉大学人民医院研究组1月...   \n",
       "9998                              闭关第二天发现一根白发2019-nCoV?   \n",
       "9999           //@高反台:昨天还在想如果有动画短片就好了，今天就有了，视频果然更直接有效吧。   \n",
       "\n",
       "                                                   微博图片  \\\n",
       "0     ['https://ww2.sinaimg.cn/thumb150/745aa591ly1g...   \n",
       "1                                                    []   \n",
       "2     ['https://ww3.sinaimg.cn/orj360/006fTidCly1gaj...   \n",
       "3                                                    []   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "9995                                                 []   \n",
       "9996  ['https://ww1.sinaimg.cn/orj360/b633842dgy1gb7...   \n",
       "9997  ['https://ww1.sinaimg.cn/orj360/72c6e287ly1gb7...   \n",
       "9998  ['https://ww1.sinaimg.cn/orj360/65eccabcly1gbb...   \n",
       "9999  ['https://wx1.sinaimg.cn/orj480/00721Ezdly1gbb...   \n",
       "\n",
       "                                                   微博视频  \n",
       "0                                                    []  \n",
       "1                                                    []  \n",
       "2                                                    []  \n",
       "3                                                    []  \n",
       "4                                                    []  \n",
       "...                                                 ...  \n",
       "9995                                                 []  \n",
       "9996                                                 []  \n",
       "9997                                                 []  \n",
       "9998                                                 []  \n",
       "9999  ['https://f.video.weibocdn.com/001wQVdllx07Aus...  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path = os.path.join('data', 'nCov_10k_test.csv')\n",
    "test_df = pd.read_csv(test_path)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "850d20de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# some arguments\n",
    "epochs = 20\n",
    "padded_size = 512\n",
    "batch_size = 8\n",
    "learning_rate = 1e-5\n",
    "ratio = 0.8\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2ee0b64f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenize_corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-eac4f1a8d27f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# train_df = pd.read_csv(train_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtokenized_train_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenized'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenize_corpus' is not defined"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join('data', 'nCoV_100k_train.labled.csv')\n",
    "# test_path = os.path.join('data', 'nCov_10k_test')\n",
    "# train_df = pd.read_csv(train_path)\n",
    "corpus,labels = get_data(train_path, 512)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"hfl/chinese-roberta-wwm-ext\")\n",
    "tokenized_train_data = tokenize_corpus(corpus, tokenizer)\n",
    "logger.info('tokenized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7a3cd430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99560/99560 [01:38<00:00, 1008.56it/s]\n",
      "[2022-08-04 16:30:13,458]-[train:INFO]: tokenized\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"hfl/chinese-roberta-wwm-ext\")\n",
    "tokenized_train_data = tokenize_corpus(corpus, tokenizer)\n",
    "logger.info('tokenized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "41e25850",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99560/99560 [00:06<00:00, 15036.67it/s]\n",
      "[2022-08-04 16:36:32,119]-[train:INFO]: masked\n"
     ]
    }
   ],
   "source": [
    "input_ids, input_types, input_masks = mask_token_ids(tokenized_train_data, padded_size)\n",
    "logger.info('masked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "71df0c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader = split_train_dataset(input_ids, input_types, input_masks,\n",
    "                                                 labels,\n",
    "                                                 batch_size,\n",
    "                                                 ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cd202497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size=768, mid_size=256):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"hfl/chinese-roberta-wwm-ext\")\n",
    "        # self.bert = BertModel.from_pretrained(\"nghuyong/ernie-gram-zh\")\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, mid_size),\n",
    "            nn.BatchNorm1d(mid_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(mid_size, 3),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        context = x[0]\n",
    "        types = x[1]\n",
    "        mask = x[2]\n",
    "\n",
    "        # _, pooled = self.bert(context, token_type_ids=types,\n",
    "        #                       attention_mask=mask,\n",
    "        #                       output_all_encoded_layers=False)\n",
    "        # last_hidden_state, pooled = self.bert(context, token_type_ids=types,\n",
    "                            #   attention_mask=mask)\n",
    "        # pooled = self.bert(context, token_type_ids=types,\n",
    "        #                       attention_mask=mask).last_hidden_state[:,1,:]\n",
    "        pooled = self.bert(context, token_type_ids=types,\n",
    "                              attention_mask=mask).pooler_output\n",
    "        # print(pooled)\n",
    "        context_embedding = self.dropout(pooled)\n",
    "\n",
    "        output = self.classifier(context_embedding)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "202eb477",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "38648314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-08-04 16:43:41,734]-[train:INFO]: +++ model init on cuda +++\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "logger.info(f\"+++ model init on {device} +++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5a1ebfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wales/.local/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "[2022-08-04 16:46:22,794]-[train:INFO]: +++ optimizer init +++\n"
     ]
    }
   ],
   "source": [
    "# optimizer\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_group_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = torch.optim.AdamW(optimizer_group_parameters,\n",
    "                     lr=learning_rate,\n",
    "                     eps=1e-8)\n",
    "logger.info(\"+++ optimizer init +++\")\n",
    "num_training_steps = int(len(train_input_ids) * ratio) * epochs\n",
    "warmup = 0.1\n",
    "num_warmup_steps = num_training_steps * warmup\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps-num_warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "10005248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, device, train_loader, optimizer, epoch, scheduler):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for batch_idx, (x1, x2, x3, y) in enumerate(train_loader):\n",
    "        x1_g, x2_g, x3_g, y_g = x1.to(device), x2.to(device), x3.to(device), y.to(device)\n",
    "        y_pred = model([x1_g, x2_g, x3_g])\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = criterion(y_pred, y_g)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # if (batch_idx + 1) % 100 == 0:\n",
    "        if (batch_idx + 1) % 500 == 0:\n",
    "            logger.info('Train Epoch: {} [{}/{} ({:.2f}%)]\\tLoss: {:.6f}'.format(epoch, (batch_idx + 1) * len(x1),\n",
    "                                                                           len(train_loader.dataset),\n",
    "                                                                           100. * batch_idx / len(train_loader),\n",
    "                                                                           loss.item()))\n",
    "\n",
    "\n",
    "def valid_step(model, device, valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    valid_true = []\n",
    "    valid_pred = []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # for batch_idx, (x1, x2, x3, y) in tqdm(enumerate(valid_loader)):\n",
    "    for batch_idx, (x1, x2, x3, y) in enumerate(valid_loader):\n",
    "        x1_g, x2_g, x3_g, y_g = x1.to(device), x2.to(device), x3.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_pred_pa_all = model([x1_g, x2_g, x3_g])\n",
    "\n",
    "        valid_loss += criterion(y_pred_pa_all, y_g)\n",
    "        batch_true = y_g.cpu()\n",
    "        batch_pred = y_pred_pa_all.detach().cpu().numpy()\n",
    "        for item in batch_pred:\n",
    "            valid_pred.append(item.argmax(0))\n",
    "        for item in np.array(batch_true):\n",
    "            valid_true.append(item)\n",
    "\n",
    "    valid_loss /= len(valid_loader)\n",
    "    logger.info('Test set: Average loss: {:.4f}'.format(valid_loss))\n",
    "    valid_true = np.array(valid_true)\n",
    "    valid_pred = np.array(valid_pred)\n",
    "    avg_acc = accuracy_score(valid_true, valid_pred)\n",
    "    avg_f1s = f1_score(valid_true, valid_pred, average='macro')\n",
    "\n",
    "    logger.info('Average: Accuracy: {:.3f}%, F1Score: {:.3f}'.format(100 * avg_acc, 100 * avg_f1s))\n",
    "    logger.info(classification_report(valid_true, valid_pred))\n",
    "\n",
    "    return avg_acc, avg_f1s, valid_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "251f9ccb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 10.76 GiB total capacity; 9.46 GiB already allocated; 95.44 MiB free; 9.51 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-0375dbb9421a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbest_acc\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-106-ac97869fdfc9>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, device, train_loader, optimizer, epoch, scheduler)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mx1_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx3_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx1_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx3_g\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-e4f76881c4e9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#                       attention_mask=mask).last_hidden_state[:,1,:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         pooled = self.bert(context, token_type_ids=types,\n\u001b[0;32m---> 29\u001b[0;31m                               attention_mask=mask).pooler_output\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;31m# print(pooled)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mcontext_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m         )\n\u001b[1;32m   1008\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m                 )\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         )\n\u001b[1;32m    479\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key_query\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 10.76 GiB total capacity; 9.46 GiB already allocated; 95.44 MiB free; 9.51 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# main train\n",
    "best_acc = 0.0\n",
    "best_epoch = 0\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_step(model, device, train_loader, optimizer, epoch, scheduler)\n",
    "    acc, fis, loss = valid_step(model, device, valid_loader)\n",
    "    if best_acc < acc:\n",
    "        best_acc = acc\n",
    "        best_epoch = epoch\n",
    "    bert_classifier_path = os.path.join(output_path, 'bert_classifier_epoch{}.pth'.format(epoch))\n",
    "logger.info(f\"+++ bert train done, best epoch: {best_epoch} +++\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
